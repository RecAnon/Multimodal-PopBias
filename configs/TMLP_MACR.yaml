# TMLP
embedding_size: 64
feat_embed_dim: 64

reg_weight: 0.0
num_fc_layers: 4
hidden_dim: 512
act_fn: 'tanh'
v_dropout: 0
t_dropout: 0
alpha1: 0.5
tau1: 1
knn_k: 10
n_ui_layers: 2
adj_tensor_path: 'adj_sampling_0.1_5.pt'
mm_image_weight: 0.1
macr_alpha: [1.e-1,1.e-2,1.e-3,1.e-4,1.e-5]
macr_beta: [1.e-1,1.e-2,1.e-3,1.e-4,1.e-5]
macr_c: [2,4,6,8,10]
macr_user_branch: True


learning_rate: 0.001
learning_rate_scheduler: [1.0, 50]
dropout: 0.8
aggr_mode: 'add'

hyper_parameters: ["macr_alpha","macr_beta","macr_c"]

# training settings
epochs: 1000
#learning_rate: 0.001
stopping_step: 20
train_batch_size: 2048
learner: adam
eval_step: 1