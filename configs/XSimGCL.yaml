# XSimGCL
embedding_size: 64
#n_layer_l_star: [[2,1],[2,2],[3,1],[3,2],[3,3],[4,1],[4,2],[4,3],[4,4]]
lambda: [0.01, 0.05, 0.1, 0.2, 0.5, 1]
eps: [0, 0.01, 0.05, 0.1, 0.2, 0.5]
tau: [0.15,0.2]
n_layer_l_star: [[2,1]]

hyper_parameters: ["tau","lambda","eps","n_layer_l_star"]

learning_rate: 0.001
learning_rate_scheduler: [1.0, 50]

# training settings
epochs: 1000
#learning_rate: 0.001
stopping_step: 5
train_batch_size: 2048
learner: adam
eval_step: 1
